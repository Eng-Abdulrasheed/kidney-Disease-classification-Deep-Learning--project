<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Web Camera Continuous Face Tracking</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    </script>
    <style>
        body {
            margin: 0;
            padding: 0;
            background-color: #fff;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        .main {
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 20px;
            overflow: hidden;
            text-align: center;
            position: absolute;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            width: 80%;
            max-width: 800px;
            display: none;
        }

        .image-part {
            position: relative;
            margin: auto;
            width: 220px;
            height: 220px;
            border-radius: 50%;
            overflow: hidden;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            display: flex;
            justify-content: center;
            align-items: center;
            background: #fff;
        }

        #video, #canvas {
            position: absolute;
            transform: scaleX(-1);
        }

        #video {
            height: 100%;
        }

        .powered-by {
            font-family: Arial, sans-serif;
            color: #aaa;
            position: absolute;
            bottom: 20px;
            left: center;
            font-size: 0.75em;
        }

        .btn-part { margin-top: 20px; text-align: center; }
        .iupload {
            padding: 20px;
            text-align: center;
        }

        .image-part::before {
            position: relative;
            margin: auto;
            width: 100vw; /* Fill the entire viewport width */
            height: 100vh; /* Fill the entire viewport height */
            border-radius: 50%; /* Circular frame */
            overflow: hidden;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            display: flex;
            justify-content: center;
            align-items: center;
            background: #fff;
        }

        #loading { 
            display: none; 
            position: fixed; 
            left: 0; 
            top: 0; 
            width: 100%; 
            height: 100%; 
            background: rgba(255,255,255,0.7); 
            z-index: 9999; 
        }
        .loader { 
            border: 8px solid #f3f3f3; 
            border-radius: 50%; 
            border-top: 8px solid #3498db; 
            width: 60px; 
            height: 60px; 
            animation: spin 2s linear infinite; 
            position: absolute; 
            left: 50%; 
            top: 50%; 
            transform: translate(-50%, -50%); 
        }
        @keyframes spin { 
            0% { transform: rotate(0deg); } 
            100% { transform: rotate(360deg); } 
        }
        .notation {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background-color: purple;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            display: none; /* Hide until the video stream starts */
        }


        .erate {
            display: none;
            position: absolute;
            height: 27px;
            width: 90px;
            background: #ff0606; /* Initial color */
            z-index: 1000;
            border-radius: 50px;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white; /* Text color */
            font-weight: bold;
            transition: background-color 0.5s ease; /* Smooth transition for background color */
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2); /* Soft shadow for depth */
            
        }
        

        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
          }
          
          .blinking {
              animation: blink 1s infinite; /* Blink every second */
          }
          .distance-message {
            font-weight: bold; /* Make the text bolder */
            color: #B8860B; /* Clear yellow color for visibility */
            font-size: 20px; /* Larger font size for clarity */
            padding: 10px; /* Some padding for better spacing */
            border: 2px solid #FFEB3B; /* Bolder line with a clear color */
            border-radius: 5px; /* Optional: adds rounded corners */
            background-color: rgba(255, 235, 59, 0.2); /* Optional: soft background color */
            margin: 20px 0; /* Adjust spacing around the message */
        }        

        #instructionContent {
            position: absolute; /* Position it absolutely within the body, which should have relative positioning */
            top: 5%; /* 5% from the top of the window */
            left: 50%; /* Centered horizontally */
            transform: translateX(-50%); /* Offset it by half its width to center align */
            width: 600px; /* Or any width you prefer */
            background: #f8f9fa; /* Light grey background */
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin: auto;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        

        
        body {
            display: flex;
            align-items: flex-start; /* Aligns the child content at the top */
            justify-content: center; /* Centers the child content horizontally */
            padding-top: 40px; /* Adds some space at the top */
            margin: 0;
        }
        
        /* You may also want to adjust the button style if needed */
        #instructionContent button#startButton {
            padding: 10px 20px;
            font-size: 18px; /* Larger font size */
            width: 100px; /* Fixed width */
            margin-top: 20px; /* Space above the button */
        }
        
        
        html, body {
            height: 100%;
            margin: 0;
            padding: 0;
            background-color: #fff; /* Set the background to white */
        }
        
        .modal-container {
            display: flex;
            justify-content: center;
            position: fixed;
            top: 0; /* Align to the top */
            left: 0;
            width: 100%;
            height: 100vh; /* Full viewport height */
            background-color: rgba(255, 255, 255, 0.9); /* White background with slight transparency */
            z-index: 1050; /* Above other elements */
            align-items: flex-start; /* Align modal content to the top */
        }
        
        .modal-content {
            margin-top: 50px; /* Distance from the top */
            background-color: #fff;
            padding: 20px;
            border-radius: 5px;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
            width: auto;
        }
        
        .modal-icon {
            width: 50px; /* Adjust as necessary */
            height: auto;
            margin-bottom: 20px;
        }
        
        
        
          
     
    </style>
</head>
<body>
    <!-- Instructional Content -->
    <div id="instructionContent" class="container" style="text-align: center; margin-top: 20px;">
        <h3>Selfie time!</h3>
        <p>Get ready:</p>
        <ul>
            <li>Good illumination.</li>
            <li>No accessories: glasses, mask, hat, etc.</li>
            <li>Camera at eye level.</li>
        </ul>
        <button type="button" class="btn btn-primary" id="startButton">Go</button>
    </div>

    <!-- Main Container (Initially Hidden) -->
    <div class="main container" style="display: none;">
        <div class="row">
            <div class="col-12 col-6">
                <section class="iupload">
                    <h3>Fintechsys Liveness System</h3>
                    <div class="distance-message" style="text-align: center; margin-bottom: 20px;"></div>
                    <div class="image-part">
                        <video id="video" autoplay playsinline></video>
                        <canvas id="canvas"></canvas>
                        
                        <div class="powered-by">Powered by Fintechsys</div>
                        <div id="erate" class="erate"></div>
                    </div>
                    
                    <h5>Prediction Results</h5>
                    <div class="res-part" style="border:1px solid #dedede; height: 310px; overflow:auto;">
                        <div class="jsonRes"></div>
                    </div>
                </section>
            </div>
        </div>
    </div>

    <div id="loading">
        <div class="loader"></div>
    </div>
    <!-- Success Message Modal (Initially Hidden) -->
    <div id="successModal" class="modal-container" style="display: none;">
        <div class="modal-content text-center">
            <img src="{{ url_for('static', filename='icons/sucess-icon.png') }}" alt="Verified" class="modal-icon mx-auto text-center">
            <h3>Verified!</h3>
            <p>Successfully verified as a live person.</p>
            <button type="button" class="btn btn-primary" id="startOverButton">Start Over</button>
        </div>
    </div>

    <!-- Failure Message Modal (Initially Hidden) -->
    <div id="failureModal" class="modal-container" style="display: none;">
        <div class="modal-content text-center">
            <img src="{{ url_for('static', filename='icons/not-sucess-icon.png') }}" alt="Not Verified" class="modal-icon  mx-auto text-center">
            <h3>Not Verified</h3>
            <p>Could not verify as a live person. Please try again.</p>
            <button type="button" class="btn btn-primary" id="tryAgainButton">Try Again</button>
        </div>
    </div>

    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/nicolaspanel/numjs@0.15.1/dist/numjs.min.js"></script> 
    <script src="{{ url_for('static', filename='js/opencv.js') }}"></script>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <!-- Include Bootstrap JS -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    

    <script>
        
        const captureButton = document.getElementById('startButton');
        
        $(document).ready(function(){
            // Assuming $("#instructionModal").modal('show'); was for the initial modal approach
            // Now, you have replaced it with direct content, so we don't need to show the modal on page load.

            // Adding the event listener to the 'Go' button
            captureButton.addEventListener('click', function(){
                // Hide the instructional content and show the main content
                $('#instructionContent').hide(); // This is the correct action for your current setup
                $('.main').show(); // Ensure the main content is shown
                startCamera();

                // Continue with your existing functionality
                if (images.length === 0) {
                    shuffleArray(styles);
                    rotateAndCapture();
                }
            });
        });

        // for sucess message or not sucess

        $(document).ready(function() {
            // Existing initialization code
        
            // Event listener for the 'Start Over' button in the success modal
            $('#startOverButton').click(function() {
                $('#successModal').hide(); // Hide the success modal
                location.reload(); // Reload the page to start over
            });
        
            // Event listener for the 'Try Again' button in the failure modal
            $('#tryAgainButton').click(function() {
                $('#failureModal').hide(); // Hide the failure modal
                location.reload(); // Reload the page to start over
            });
        });

        // initial the camera 
        let mediaRecorder;
        let recordedChunks = [];

        function startCamera() {
            navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } })
                .then(function(stream) {
                    video.srcObject = stream;
                    video.onloadedmetadata = function() {
                        adjustVideoCanvasSize();
                        video.play();
                        startRecording(); // Start recording video frames
                        onFrame();
                    };
                })
                .catch(function(error) {
                    console.error("Camera access error:", error);
                    alert("Could not access the camera. Error: " + error.name);
                });
        }

        function startRecording() {
            mediaRecorder = new MediaRecorder(video.srcObject);
            mediaRecorder.ondataavailable = handleDataAvailable;
            mediaRecorder.start();
        }

        function handleDataAvailable(event) {
            if (event.data.size > 0) {
                recordedChunks.push(event.data);
                sendData(event.data);
            }
        }

        async function sendData(data) {
            const formData = new FormData();
            formData.append('video_frames', data);
            try {
                const response = await fetch('/receive_video_frames', {
                    method: 'POST',
                    body: formData
                });
                const result = await response.json();
                console.log(result.message);
            } catch (error) {
                console.error('Error sending data:', error);
            }
        }

        function stopCamera() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            video.srcObject = null;
            recordedChunks = [];
        }

        
        
        
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        var faceDirection;

        const faceMesh = new FaceMesh({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
        });
        faceMesh.setOptions({
            maxNumFaces: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
            refineLandmarks: true,
        });
        faceDirection =  faceMesh.onResults(onResults);
       // console.log("Onresult face direction",faceDirection);
        
    
        // Define an array of style configurations
        var styles = [
            { left: '-30px', transform: 'rotate(-90deg)', right: '', top: '', bottom: '' }, // Style One
            { right: '-30px', transform: 'rotate(-90deg)', left: '', top: '', bottom: '' }, // Style Two
            { bottom: '0', transform: 'rotate(0deg)', left: '', top: '', right: '' }, // Style Three
            { top: '0', transform: 'rotate(0deg)', left: '', bottom: '', right: '' }, // Style Four
            { top: '6%', right: '0', transform: 'rotate(40deg)', left: '', bottom: '' }, // Style Five
            { top: '6%', left: '0', transform: 'rotate(-40deg)', right: '', bottom: '' }, // Style Six
            { bottom: '6%', left: '0', transform: 'rotate(40deg)', right: '', top: '' }, // Style Seven
            { bottom: '6%', right: '0', transform: 'rotate(-40deg)', left: '', top: '' } // Style Eight
        ];
    
        function onOpenCvReady() {
            console.log('OpenCV.js is ready.');
            // Initialize FaceMesh or any other operations that require cv here
            initializeFaceMesh();
        }

        
        let images = [];
       // let images_dir = [];
        let captureIndex = 0;
        
    
        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }
    
        function applyStyle(style) {
            const erateElement = document.querySelector('.erate');
            erateElement.style.left = style.left;
            erateElement.style.right = style.right;
            erateElement.style.top = style.top;
            erateElement.style.bottom = style.bottom;
            erateElement.style.transform = style.transform;
        }
        const width_img = 480;
        const height_img = 320;
    
        function captureImage() {
            captureIndex++;
            adjustVideoCanvasSize();
            context.drawImage(video, 0, 0,width_img, height_img); 
            var base64data = canvas.toDataURL('image/jpeg').replace(/^data:image\/jpeg;base64,/, '');
            images.push(base64data);
    
            if (images.length === 8) {
                sendImagesForPrediction(images);
                images = []; // Reset the images array for next time
                captureIndex = 0; // Reset capture index
                // Stop the sequence, no need to explicitly stop as it will not continue automatically
            } else {
                setTimeout(() => {
                    // Proceed to the next capture after a delay
                    rotateAndCapture();
                }, 1000); // 6 seconds for each capture cycle
            }
        }
        // Determine the style of the erate element
        function determineExpectedDirection(style) {
            // Simplified logic based on your style definitions
            if (style.left) return "Left";
            if (style.right) return "Right";
            if (style.top) return "Up";
            if (style.bottom) return "Down";
            // Extend this logic based on your actual style-to-direction mappings
            return "Forward"; // Fallback direction
        }


    
        // Step 3: Access the global variable in rotateAndCapture

        function checkLighting() {
            const canvasContext = canvas.getContext('2d');
            canvasContext.drawImage(video, 0, 0, width_img, height_img);
            const imageData = canvasContext.getImageData(0, 0, width_img, height_img);
            let totalBrightness = 0;
        
            for (let i = 0; i < imageData.data.length; i += 4) {
                // Convert the color to grayscale using luminance formula
                totalBrightness += 0.2126 * imageData.data[i] + 0.7152 * imageData.data[i + 1] + 0.0722 * imageData.data[i + 2];
            }
        
            const avgBrightness = totalBrightness / (width_img * height_img);
            return avgBrightness;
        }

        
        function rotateAndCapture() {
            if (captureIndex < styles.length) {
                const currentStyle = styles[captureIndex];
                applyStyle(currentStyle);
        
                let attemptStartTime = Date.now(); // Track the start time of this attempt
        
                const checkDirectionAndDistanceAndCapture = () => {
                    const erateElement = document.getElementById('erate');
                    const distanceMessageElement = document.querySelector('.distance-message');
                    const expectedDirection = determineExpectedDirection(currentStyle);
                    const avgBrightness = checkLighting(); // Check the lighting here
        
                    // Define thresholds
                    const brightnessThreshold = 70; // Adjust this threshold based on your needs
                    const minDistanceThreshold = 30;
                    const maxDistanceThreshold = 40;
                    
                    // Check if the distance is within the acceptable range and if the brightness is good
                    if (lastCalculatedDistance >= minDistanceThreshold && lastCalculatedDistance <= maxDistanceThreshold && avgBrightness >= brightnessThreshold) {
                        distanceMessageElement.textContent = ''; // Clear any previous message
                        console.log(avgBrightness)
                        let elapsedTime = Date.now() - attemptStartTime;
        
                        if (globalFaceDirection === expectedDirection) {
                            erateElement.style.backgroundColor = "#4CAF50"; // Green color for success
                            erateElement.classList.remove("blinking"); // Stop blinking on match
                            setTimeout(() => {
                                captureImage();
                            }, 500);
                        } else if (elapsedTime <= 8000) {
                            erateElement.style.backgroundColor = "#FF5733"; // Red color for attention
                            erateElement.classList.add("blinking"); // Continue blinking to indicate mismatch
                            setTimeout(checkDirectionAndDistanceAndCapture, 200); // Check more frequently within the 5-second window
                        } else {
                            displayFailureMessage("Please adjust your position and try again.");
                        }
                    } else {
                        // Handle cases for poor distance or lighting
                        if (avgBrightness < brightnessThreshold) {
                            distanceMessageElement.textContent = "اختر اضاءة جيدة";
                        } else if (lastCalculatedDistance < minDistanceThreshold) {
                            distanceMessageElement.textContent = "من فضلك ابتعد قليلا عن الكاميرا";
                        } else if (lastCalculatedDistance > maxDistanceThreshold) {
                            distanceMessageElement.textContent = "فضلا..عليك الاقتراب قليلا من الكامير";
                        }
        
                        erateElement.style.backgroundColor = "#FFEB3B"; // Yellow color for warning
                        setTimeout(checkDirectionAndDistanceAndCapture, 2000); // Re-check after some time
                    }
                };
        
                setTimeout(checkDirectionAndDistanceAndCapture, 500); // Initial direction check after a short delay
            } else {
                console.log("Session completed or no styles to process.");
            }
        }
        
        
        
        function displayFailureMessage() {
            // Show failure message with a "Start Over" button
            document.querySelector('.res-part').innerHTML = `
                <div class="alert alert-danger" role="alert">
                    Face direction not correct. Start again.
                </div>
                <button type="button" class="btn btn-primary" id="start-over">Start Over</button>
            `;
        
            // Setup "Start Over" button to reset the process
            document.getElementById('start-over').addEventListener('click', function() {
                location.reload(); // Reload the page to start over
            });
        }
        
        
        



        function sendImagesForPrediction(images) {
            $("#loading").show();
            $.ajax({
                url: "/predict",
                type: "POST",
                data: JSON.stringify({ images: images }),
                contentType: "application/json; charset=utf-8",
                dataType: "json",
                success: function(response) {
                    $("#loading").hide();
                    $('.main').hide(); // Hide the main model
                    stopCamera();
                    if (response.average_prediction > 0.1) {
                        $('#successModal').show(); // Show success modal
                    } else {
                        $('#failureModal').show(); // Show failure modal
                    }
                },
                error: function(err) {
                    $("#loading").hide();
                    console.error("Error in sending/receiving data.", err);
                    // Optionally, handle the error by showing the failureModal
                    $('.main').hide(); // Hide the main model
                    $('#failureModal').show(); // Show failure modal
                }
            });
        }
               
        
        function adjustVideoCanvasSize() {
            canvas.width = width_img;
            canvas.height = video.videoHeight;
        }
        // Your existing mediaDevices and FaceMesh setup here
        // No changes needed for those parts
       /*
        if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {

            
            navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } }) // Prefer the front camera on mobile devices
            .then(function(stream) {
                video.srcObject = stream;
                video.onloadedmetadata = adjustVideoCanvasSize; // Adjust size after video starts playing
            })
            .catch(function(err) {
                console.log("An error occurred: " + err);
            });
        }
       */
    
        captureButton.addEventListener('click', function() {
    
            adjustVideoCanvasSize(); // Ensure canvas size is correct at the moment of capture
            context.drawImage(video, 0, 0, width_img, height_img);
            var base64data = canvas.toDataURL('image/jpeg').replace(/^data:image\/jpeg;base64,/, '');
            
            $("#loading").show();
            $.ajax({
                url: "../predict", // Ensure this URL matches your server's endpoint
                type: "POST",
                data: JSON.stringify({ image: base64data }),
                contentType: "application/json; charset=utf-8",
                dataType: "json",
                success: function(response) {
                    $("#loading").hide();
                },
                error: function(err) {
                    console.error("Error in sending/receiving data.", err);
                    $("#loading").hide();
                }
            });
    
        });
        
        let globalFaceDirection; // Step 1: Define a global variable
        let lastCalculatedDistance = 0; // Initialize with 0 or suitable default value


        // Step 2: Update the global variable within onResults
        function onResults(results) {
            context.save();
            context.clearRect(0, 0, width_img, height_img);
            context.drawImage(results.image, 0, 0, width_img, height_img);
            // Compute the depth of z axes from the left eye
            var width = results.image.width;
            var height = results.image.height;
           // console.log(width);
           // console.log(height);
            var irisLeftMinX = Infinity; // Initialize to Infinity for min comparison
            var irisLeftMaxX = -Infinity; // Initialize to -Infinity for max comparison
        
            if (results.multiFaceLandmarks) {
                for (const landmarks of results.multiFaceLandmarks) {
                    drawConnectors(context, landmarks, FACEMESH_TESSELATION, { color: '#C0C0C070', lineWidth: 1 });
                    globalFaceDirection = getDirection(landmarks); // Update the global variable
        
                    for (const point of FACEMESH_LEFT_IRIS) {
                        if (landmarks[point[0]]) {
                            var point0 = landmarks[point[0]];
                           // console.log(point0);
                            //console.log(point0.z);
        
                            if (irisLeftMinX == -1 || point0.x * width < irisLeftMinX) {
                                irisLeftMinX = point0.x * width;
                            }
                            if (irisLeftMaxX == -1 || point0.x * width > irisLeftMaxX) {
                                irisLeftMaxX = point0.x * width;
                            }
                        }
                    }
                    
                    // Ensure you break after the first face for efficiency, if that's your intention
                    break; // This breaks out of the multiFaceLandmarks loop
                }
            }
        
            // Ensure irisLeftMinX and irisLeftMaxX have been updated correctly
            var dx = irisLeftMaxX - irisLeftMinX;
            if (dx > 0) { // Ensure dx is not zero to avoid division by zero
                var dX = 11.7;
                // Logitech HD Pro C922 Norm focal
                var normalizedFocaleX = 1.40625;
                var fx = Math.min(width, height) * normalizedFocaleX;
                var dZ = (fx * (dX / dx)) / 10.0;
                dZ = dZ.toFixed(2);
                console.log(dZ, "Cm");
                lastCalculatedDistance = dZ;
            } else {
                console.log("Invalid iris dimensions for depth calculation.");
            }
        
            context.restore();
        }
        
            


                        // Assuming the necessary OpenCV.js library is loaded and available as cv
            // Also assuming context, video, canvas are already defined and set up for capturing and displaying video frames

            function adjustVideoCanvasSize() {
                // Adjust canvas size to match video stream size
                canvas.width = width_img;
                canvas.height = height_img;
            }
                        
            function estimateDirection(translation_vec) {
                let direction = "Forward"; // Default direction
            
                // Access the translation vector components
                let tx = translation_vec.doubleAt(0); // Horizontal movement
                let ty = translation_vec.doubleAt(1); // Vertical movement
               // console.log(translation_vec.doubleAt(2));
            
                // Adjust thresholds if necessary, based on observation
                const thresholdX = 8;
                const thresholdY = 8;
            
                // Determine primary direction
                if (Math.abs(tx) > Math.abs(ty)) { // Horizontal movement is more significant
                    if (tx > thresholdX) { // Note the inversion of comparison operator
                        direction = "Left"; // Assuming positive tx is to the subject's right, which is "Left" from the observer's perspective
                    } else if (tx < -thresholdX) {
                        direction = "Right"; // Negative tx to the subject's left, "Right" from observer's view
                    }
                } else { // Vertical movement is more significant
                    if (ty > thresholdY) { // Note the inversion of comparison operator
                        direction = "Down"; // Assuming positive ty is downward movement
                    } else if (ty < -thresholdY) {
                        direction = "Up"; // Negative ty is upward movement
                    }
                }
            
                // Update the webpage with the estimated direction
                const erateElement = document.getElementById('erate');
               // erateElement.textContent = direction;
                erateElement.style.display = 'block'; // Ensure the element is visible
            
              // console.log("Estimated Direction:", direction);
               return direction
            }

            function getDirection(landmarks) {
                adjustVideoCanvasSize();
                context.drawImage(video, 0, 0, width_img, height_img);

                let face_2d = [];
                let face_3d = [];
                let img_w = width_img;
                let img_h = height_img;

                // Define 3D model points.
                let modelPoints = [
                    [0.0, 0.0, 0.0],    // Nose tip
                    [0.0, -330.0, -65.0], // Chin
                    [-225.0, 170.0, -135.0], // Left eye left corner
                    [225.0, 170.0, -135.0], // Right eye right corner
                    [-150.0, -150.0, -125.0], // Left Mouth corner
                    [150.0, -150.0, -125.0]  // Right mouth corner
                ];

                landmarks.forEach((lm, idx) => {
                    // Example landmark indices, replace with actual indices for the nose tip, chin, eyes corners, mouth corners
                    if ([33, 263, 1, 61, 291, 199].includes(idx)) {
                        let x = lm.x * img_w;
                        let y = lm.y * img_h;
                        face_2d.push([x, y]);
                        // Use modelPoints for 3D face points
                        face_3d.push(modelPoints.shift());
                    }
                });

                if (face_2d.length !== 6 || face_3d.length !== 6) {
                    console.log("Insufficient points for pose estimation");
                    return;
                }

                let face_2d_mat = cv.matFromArray(face_2d.length, 2, cv.CV_64FC1, [].concat(...face_2d));
                let face_3d_mat = cv.matFromArray(face_3d.length, 3, cv.CV_64FC1, [].concat(...face_3d));

                let focal_length = img_w;
                let center = [img_w / 2, img_h / 2];
                let cam_matrix = cv.matFromArray(3, 3, cv.CV_64FC1, [
                    focal_length, 0, center[0],
                    0, focal_length, center[1],
                    0, 0, 1,
                ]);

                let dist_coeffs = cv.Mat.zeros(4, 1, cv.CV_64F);

                let rotation_vec = new cv.Mat();
                let translation_vec = new cv.Mat();

                let success = cv.solvePnP(face_3d_mat, face_2d_mat, cam_matrix, dist_coeffs, rotation_vec, translation_vec, false, cv.SOLVEPNP_ITERATIVE);

                if (!success) {
                    console.log("Pose estimation failed");
                    return;
                }

                // Directly estimate direction based on translation vector

                let direction =  estimateDirection(translation_vec); 
                
               // console.log("Pose estimation succeeded:", direction);

                // Assuming success, we proceed, but note that actual direction determination logic is missing here
               // console.log("Pose estimation succeeded");

                // Cleanup
                face_2d_mat.delete(); face_3d_mat.delete();
                cam_matrix.delete(); dist_coeffs.delete();
                rotation_vec.delete(); translation_vec.delete();

                return direction;
            }

            // Example usage of getDirection function, assuming landmarks are obtained from a facial landmark detection library



    
            function onFrame() {
                faceMesh.send({image: video}).finally(() => {
                    window.requestAnimationFrame(onFrame);
                });
            }
    



            
           /*
            navigator.mediaDevices.getUserMedia({video: true})
                .then((stream) => {
                    video.srcObject = stream;
                    video.onloadedmetadata = (e) => {
                        video.play();
                        canvas.width = width_img;
                        canvas.height = height_img;
                        onFrame(); // Start the frame processing loop
                    };
                })
                .catch((error) => {
                    console.error(error);
                    alert("Could not access the camera. Error: " + error.name);
                });
           */
               
    </script>
    
</body>
</html>